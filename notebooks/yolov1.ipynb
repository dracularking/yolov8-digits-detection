{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.yolo.v1.dataset import YOLOv1Dataset\n",
    "from src.yolo.v1.model import YOLOv1Model\n",
    "from src.yolo.v1.loss import YOLOv1Loss\n",
    "from src.yolo.utils import calculate_boxes_iou\n",
    "from src.utils.utils import DATA_PATH\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose(\n",
    "    [\n",
    "        A.LongestMaxSize(max_size=448, interpolation=1),\n",
    "        A.PadIfNeeded(min_height=448, min_width=448, border_mode=0, value=(0, 0, 0)),\n",
    "        A.Rotate(limit=10, border_mode=cv2.BORDER_REPLICATE, p=1),\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(format=\"yolo\", label_fields=[\"labels\"], min_visibility=0.7),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 7\n",
    "C = 10\n",
    "B = 2\n",
    "\n",
    "ds = YOLOv1Dataset(S, C, B, DATA_PATH / \"yolo_HWD+\", transform=transform)\n",
    "model = YOLOv1Model(S, C, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, annots = ds[0]\n",
    "img = torch.Tensor(img).permute(2, 0, 1)\n",
    "out = model(img.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = annots.unsqueeze(0)\n",
    "preds = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = torch.nn.MSELoss(reduction=\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_iou = []\n",
    "for box_idx in range(B):\n",
    "    box_start_idx = C + 1 + box_idx * 5\n",
    "    box_end_idx = box_start_idx + 5\n",
    "    box_iou = calculate_boxes_iou(\n",
    "        preds[..., box_start_idx:box_end_idx], targets[..., C + 1 : C + 5]\n",
    "    ).squeeze(-1)\n",
    "    boxes_iou.append(box_iou.unsqueeze(0))\n",
    "\n",
    "ious = torch.cat(boxes_iou, dim=0)\n",
    "\n",
    "iou_maxes, bestbox_idxs = torch.max(ious, dim=0)\n",
    "obj_mask = targets[..., C] == 1  # Iobj_i\n",
    "\n",
    "bestbox_idxs = bestbox_idxs[obj_mask]  # only idxs with objects\n",
    "\n",
    "# Coord loss\n",
    "obj_preds = preds[obj_mask]  # only preds with objects\n",
    "obj_targets = targets[obj_mask]  # only targets with objects\n",
    "\n",
    "noobj_preds = preds[~obj_mask]  # only preds without objects\n",
    "noobj_targets = targets[~obj_mask]  # only targets without objects\n",
    "\n",
    "idxs = torch.tensor([range(box_idx * 5 + C + 1, box_idx * 5 + C + 5) for box_idx in bestbox_idxs])\n",
    "obj_box_preds = obj_preds.gather(1, idxs)\n",
    "obj_box_targets = obj_targets[:, C + 1 : C + 5]\n",
    "\n",
    "obj_box_preds[:, 2:] = torch.sign(obj_box_preds[:, 2:]) * torch.sqrt(\n",
    "    abs(obj_box_preds[:, 2:]) + 1e-10\n",
    ")\n",
    "obj_box_targets[:, 2:] = torch.sqrt(obj_box_targets[:, 2:])\n",
    "\n",
    "coord_loss = mse(obj_box_preds.flatten(), obj_box_targets.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_object_preds = obj_preds[:, C]\n",
    "obj_object_targets = obj_targets[:, C]\n",
    "object_loss = mse(obj_object_preds, obj_object_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2286, -0.0132,  0.2917,  0.4485],\n",
       "        [ 0.0432, -0.3115,  0.3230, -0.1297],\n",
       "        [-0.0113, -0.2784,  0.6748,  0.4544],\n",
       "        [-0.1606,  0.1319,  0.5168,  0.5707],\n",
       "        [-0.0621, -0.0523,  0.4084, -0.0588]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_box_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 20])"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "noobj_object_preds = noobj_preds[:, C]\n",
    "noobj_object_targets = noobj_targets[:, C]\n",
    "noobject_loss = mse(noobj_object_preds, noobj_object_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_class_preds = obj_preds[:, :C]\n",
    "obj_class_targets = obj_targets[:, :C]\n",
    "class_loss = mse(torch.flatten(obj_class_preds), torch.flatten(obj_class_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 5 * coord_loss + object_loss + 0.5 * noobject_loss + class_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = YOLOv1Loss(C, B, 5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14.0815, grad_fn=<MseLossBackward0>) tensor(4.6638, grad_fn=<MseLossBackward0>) tensor(3.5814, grad_fn=<MseLossBackward0>) tensor(6.9436, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(83.8056, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(preds, targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "digits-detection-hppNHGvS-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
